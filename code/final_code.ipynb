{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Science: Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "This includes:   \n",
    "* Importing libraries\n",
    "* Defining functions\n",
    "* Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx #network analysis\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #viz\n",
    "import random \n",
    "import pandas as pd #to manipulate data frames\n",
    "import math #for logarithm in entropy formula\n",
    "from IPython.display import display\n",
    "import os #files manipulation\n",
    "\n",
    "#if you're working on google colab, uncomment the following line\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/net-sci-project-master/net-sci-project-master/code')\n",
    "# os.getwcd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions\n",
    "\n",
    "Functions to:  \n",
    "* compute LCC\n",
    "* compute I index\n",
    "* compute R measure\n",
    "* compute Interval E\n",
    "* Apply Random Attack\n",
    "* Apply Targeted Attack (takes a graph and sorted list of nodes and returns dictions of metrics: LCC, I, efficiency)\n",
    "* Apply Community ased attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lcc(G):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        max_comp= max(nx.connected_components(G), key=len)\n",
    "        return len(max_comp)\n",
    "    \n",
    "def compute_i(G, i):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        max_comp= max(nx.connected_components(G), key=len)\n",
    "        return len(max_comp)/i\n",
    "\n",
    "def compute_r(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    SUM=0\n",
    "    N= G.number_of_nodes()\n",
    "\n",
    "    if type(sorted_nodes[0])==tuple:\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            n=sorted_nodes[i][0]\n",
    "            G.remove_node(n)\n",
    "            lcc= compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "    else:\n",
    "        for i in range(N):\n",
    "\n",
    "            n=sorted_nodes[i]\n",
    "            G.remove_node(n)\n",
    "            lcc= compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "\n",
    "    return SUM/N\n",
    "\n",
    "def compute_r_50_batches(attack):\n",
    "    '''takes a tuple of dictionaries (output of attack) that contains the lcc of attack'''\n",
    "    lcc_attack=attack[3]\n",
    "    r = sum(list(lcc_attack.values()))/len(list(lcc_attack.values()))\n",
    "    return r\n",
    "\n",
    "def compute_r_100_batches(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    N=G.number_of_nodes()\n",
    "    batch_size = N//100\n",
    "    SUM=0\n",
    "    if type(sorted_nodes[0])==tuple:\n",
    "\n",
    "        for i in range(50):\n",
    "            for j in range(batch_size):\n",
    "                n = sorted_nodes[i*batch_size+j][0]\n",
    "                G.remove_node(n)\n",
    "            lcc = compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "    \n",
    "    else:\n",
    "        for i in range(50):\n",
    "            for j in range(batch_size):\n",
    "                n = sorted_nodes[i*batch_size+j]\n",
    "                G.remove_node(n)\n",
    "            lcc = compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "\n",
    "    return SUM/100\n",
    "\n",
    "\n",
    "def random_attack(g):\n",
    "    G=g.copy()\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes)\n",
    "    #divide the nodes into 100 batches\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            n = nodes[i*batch_size+j]\n",
    "            G.remove_node(n)\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        LCC[i] = lcc/fix\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return LCC, Inter, E\n",
    "\n",
    "def random_attack_edge(g):\n",
    "    '''returns the graph after a random attack of the edge'''\n",
    "    G = g.copy()\n",
    "    edges = list(G.edges())\n",
    "    random.shuffle(edges)\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            e = edges[i*batch_size+j]\n",
    "            G.remove_edge(e[0], e[1])\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        LCC[i] = lcc/fix\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return LCC, Inter, E\n",
    "\n",
    "def attack(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    norm_LCC={}\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            n = sorted_nodes[i*batch_size+j]\n",
    "            G.remove_node(n)\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        norm_LCC[i] = lcc/fix\n",
    "        LCC[i]=lcc\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return norm_LCC, Inter, E, LCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading networks\n",
    "\n",
    "* Loading the network\n",
    "* Extract some properties:\n",
    "  * Compute statistics\n",
    "  * Get degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arenas_email = nx.read_gml('../benchmark/arenas-email.gml', label='id')\n",
    "bn_cat_mixed_species_brain_1 = nx.read_gml('../benchmark/bn-cat-mixed-species_brain_1.gml', label='id')\n",
    "bn_macaque_rhesus_brain_2 = nx.read_gml('../benchmark/bn-macaque-rhesus_brain_2.gml', label='id')\n",
    "circuits_s208 = nx.read_gml('../benchmark/circuits s208.gml', label='id')\n",
    "circuits_s420 = nx.read_gml('../benchmark/circuits s420.gml', label='id')\n",
    "circuits_s838 = nx.read_gml('../benchmark/circuits s838.gml', label='id')\n",
    "dolphins = nx.read_gml('../benchmark/dolphins.gml', label='id')\n",
    "e_coli = nx.read_gml('../benchmark/E. coli.gml', label='id')\n",
    "facebook_0 = nx.read_gml('../benchmark/facebook 0.gml', label='id')\n",
    "facebook_107 = nx.read_gml('../benchmark/facebook 107.gml', label='id')\n",
    "facebook_1684 = nx.read_gml('../benchmark/facebook 1684.gml', label='id')\n",
    "facebook_348 = nx.read_gml('../benchmark/facebook 348.gml', label='id')\n",
    "facebook_414 = nx.read_gml('../benchmark/facebook 414.gml', label='id')\n",
    "facebook_686 = nx.read_gml('../benchmark/facebook 686.gml', label='id')\n",
    "fb_pages_food = nx.read_gml('../benchmark/fb-pages-food.gml', label='id')\n",
    "karate = nx.read_gml('../benchmark/Karate.gml', label='id')\n",
    "polbooks = nx.read_gml('../benchmark/polbooks.gml', label='id')\n",
    "soc_firm_hi_tech = nx.read_gml('../benchmark/soc-firm-hi-tech.gml', label='id')\n",
    "soc_tribes = nx.read_gml('../benchmark/soc-tribes.gml', label='id')\n",
    "word_adjacencies = nx.read_gml('../benchmark/word_adjacencies.gml', label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_911 = nx.read_edgelist('../benchmark/911.txt', nodetype=int)\n",
    "corruption = nx.read_edgelist('../benchmark/corruption.txt', nodetype=int)\n",
    "crime_net = nx.read_edgelist('../benchmark/CrimeNet.txt', nodetype=int)\n",
    "digg = nx.read_edgelist('../benchmark/Digg.txt', nodetype=int)\n",
    "email = nx.read_edgelist('../benchmark/Email.txt', nodetype=int)\n",
    "jazz = nx.read_edgelist('../benchmark/Jazz.txt', nodetype=int)\n",
    "petster_hamster = nx.read_edgelist('../benchmark/Petster-Petster.txt', nodetype=int)\n",
    "router = nx.read_edgelist('../benchmark/Router.txt', nodetype=int)\n",
    "\n",
    "#transfrm them to .gml files in benchmark folder\n",
    "nx.write_gml(net_911, '../benchmark/911.gml')\n",
    "nx.write_gml(corruption, '../benchmark/corruption.gml')\n",
    "nx.write_gml(crime_net, '../benchmark/CrimeNet.gml')\n",
    "nx.write_gml(digg, '../benchmark/Digg.gml')\n",
    "nx.write_gml(email, '../benchmark/Email.gml')\n",
    "nx.write_gml(jazz, '../benchmark/Jazz.gml')\n",
    "nx.write_gml(petster_hamster, '../benchmark/Petster-Hamster.gml')\n",
    "nx.write_gml(router, '../benchmark/Router.gml')\n",
    "\n",
    "net_911=nx.read_gml('../benchmark/911.gml', label='id')\n",
    "corruption=nx.read_gml('../benchmark/corruption.gml', label='id')\n",
    "crime_net=nx.read_gml('../benchmark/CrimeNet.gml', label='id')\n",
    "digg=nx.read_gml('../benchmark/Digg.gml', label='id')\n",
    "email=nx.read_gml('../benchmark/Email.gml', label='id')\n",
    "jazz=nx.read_gml('../benchmark/Jazz.gml', label='id')\n",
    "petster_hamster=nx.read_gml('../benchmark/Petster-Hamster.gml', label='id')\n",
    "router=nx.read_gml('../benchmark/Router.gml', label='id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Attack\n",
    "\n",
    "Random attacks applied to all the networks, all are divided to 100 batches, attack is up to 50% of the nodes/edges:\n",
    "* nodes attacks \n",
    "* edges attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------#\n",
    "#nodes random attacks:\n",
    "\n",
    "random_arenas_email_attack = random_attack(arenas_email)\n",
    "random_bn_cat_mixed_species_brain_1_attack = random_attack(bn_cat_mixed_species_brain_1)\n",
    "random_bn_macaque_rhesus_brain_2_attack = random_attack(bn_macaque_rhesus_brain_2)\n",
    "random_circuits_s208_attack = random_attack(circuits_s208)\n",
    "random_circuits_s420_attack = random_attack(circuits_s420)\n",
    "random_circuits_s838_attack = random_attack(circuits_s838)\n",
    "random_dolphins_attack = random_attack(dolphins)\n",
    "random_e_coli_attack = random_attack(e_coli)\n",
    "random_facebook_0_attack = random_attack(facebook_0)\n",
    "random_facebook_107_attack = random_attack(facebook_107)\n",
    "random_facebook_1684_attack = random_attack(facebook_1684)\n",
    "random_facebook_348_attack = random_attack(facebook_348)\n",
    "random_facebook_414_attack = random_attack(facebook_414)\n",
    "random_facebook_686_attack = random_attack(facebook_686)\n",
    "random_fb_pages_food_attack = random_attack(fb_pages_food)\n",
    "random_karate_attack = random_attack(karate)\n",
    "random_polbooks_attack = random_attack(polbooks)\n",
    "random_soc_firm_hi_tech_attack = random_attack(soc_firm_hi_tech)\n",
    "random_soc_tribes_attack = random_attack(soc_tribes)\n",
    "random_word_adjacencies_attack = random_attack(word_adjacencies)\n",
    "\n",
    "random_net911_attack = random_attack(net_911)\n",
    "random_corruption_attack = random_attack(corruption)\n",
    "random_crime_net_attack = random_attack(crime_net)\n",
    "random_email_attack = random_attack(email)\n",
    "random_jazz_attack = random_attack(jazz)\n",
    "random_petster_hamster_attack = random_attack(petster_hamster)\n",
    "random_router_attack = random_attack(router)\n",
    "# random_digg_attack = random_attack(digg)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------#\n",
    "#edges random attacks:\n",
    "\n",
    "random_arenas_email_attack_edge= random_attack_edge(arenas_email)\n",
    "random_bn_cat_mixed_species_brain_1_attack_edge= random_attack_edge(bn_cat_mixed_species_brain_1)\n",
    "random_bn_macaque_rhesus_brain_2_attack_edge= random_attack_edge(bn_macaque_rhesus_brain_2)\n",
    "random_circuits_s208_attack_edge= random_attack_edge(circuits_s208)\n",
    "random_circuits_s420_attack_edge= random_attack_edge(circuits_s420)\n",
    "random_circuits_s838_attack_edge= random_attack_edge(circuits_s838)\n",
    "random_dolphins_attack_edge= random_attack_edge(dolphins)\n",
    "random_e_coli_attack_edge= random_attack_edge(e_coli)\n",
    "random_facebook_0_attack_edge= random_attack_edge(facebook_0)\n",
    "random_facebook_107_attack_edge= random_attack_edge(facebook_107)\n",
    "random_facebook_1684_attack_edge= random_attack_edge(facebook_1684)\n",
    "random_facebook_348_attack_edge= random_attack_edge(facebook_348)\n",
    "random_facebook_414_attack_edge= random_attack_edge(facebook_414)\n",
    "random_facebook_686_attack_edge= random_attack_edge(facebook_686)\n",
    "random_fb_pages_food_attack_edge= random_attack_edge(fb_pages_food)\n",
    "random_karate_attack_edge= random_attack_edge(karate)\n",
    "random_polbooks_attack_edge= random_attack_edge(polbooks)\n",
    "random_soc_firm_hi_tech_attack_edge= random_attack_edge(soc_firm_hi_tech)\n",
    "random_soc_tribes_attack_edge= random_attack_edge(soc_tribes)\n",
    "random_word_adjacencies_attack_edge= random_attack_edge(word_adjacencies)\n",
    "\n",
    "random_net911_attack_edge= random_attack_edge(net_911)\n",
    "random_corruption_attack_edge= random_attack_edge(corruption)\n",
    "random_crime_net_attack_edge= random_attack_edge(crime_net)\n",
    "random_email_attack_edge= random_attack_edge(email)\n",
    "random_jazz_attack_edge= random_attack_edge(jazz)\n",
    "random_petster_hamster_attack_edge= random_attack_edge(petster_hamster)\n",
    "random_router_attack_edge= random_attack_edge(router)\n",
    "# random_digg_attack_edge= random_attack_edge(digg)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality-based Targeted Attack\n",
    "---------------------------\n",
    "\n",
    "* Nodes centralities:\n",
    "  * Betweenness centrality\n",
    "  * Closeness centrality\n",
    "  * Degree centrality\n",
    "  * PLCi centrality\n",
    "  * Percolaion centrality\n",
    "  * Proximity centrality\n",
    "  * Mapping Entropy Betweenness centrality\n",
    "  * Mapping Entropy Closeness centrality\n",
    "  * Mapping Entropy Degree centrality   \n",
    "\n",
    "----------------\n",
    "\n",
    "* Edges centralities:\n",
    "  * Betweenness centrality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
