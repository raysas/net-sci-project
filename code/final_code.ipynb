{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Science: Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "This includes:   \n",
    "* Importing libraries\n",
    "* Defining functions\n",
    "* Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx #network analysis\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #viz\n",
    "import random \n",
    "import pandas as pd #to manipulate data frames\n",
    "import math #for logarithm in entropy formula\n",
    "from IPython.display import display\n",
    "import os #files manipulation\n",
    "\n",
    "#if you're working on google colab, uncomment the following line\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/net-sci-project-master/net-sci-project-master/code')\n",
    "# os.getwcd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions\n",
    "\n",
    "Functions to:  \n",
    "* compute LCC\n",
    "* compute I index\n",
    "* compute R measure\n",
    "* compute Interval E\n",
    "* Apply Random Attack\n",
    "* Apply Targeted Attack (takes a graph and sorted list of nodes and returns dictions of metrics: LCC, I, efficiency)\n",
    "* Apply Community ased attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lcc(G):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        max_comp= max(nx.connected_components(G), key=len)\n",
    "        return len(max_comp)\n",
    "    \n",
    "def compute_i(G, i):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        max_comp= max(nx.connected_components(G), key=len)\n",
    "        return len(max_comp)/i\n",
    "\n",
    "def compute_r(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    SUM=0\n",
    "    N= G.number_of_nodes()\n",
    "\n",
    "    if type(sorted_nodes[0])==tuple:\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            n=sorted_nodes[i][0]\n",
    "            G.remove_node(n)\n",
    "            lcc= compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "    else:\n",
    "        for i in range(N):\n",
    "\n",
    "            n=sorted_nodes[i]\n",
    "            G.remove_node(n)\n",
    "            lcc= compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "\n",
    "    return SUM/N\n",
    "\n",
    "def compute_r_50_batches(attack):\n",
    "    '''takes a tuple of dictionaries (output of attack) that contains the lcc of attack'''\n",
    "    lcc_attack=attack[3]\n",
    "    r = sum(list(lcc_attack.values()))/len(list(lcc_attack.values()))\n",
    "    return r\n",
    "\n",
    "def compute_r_100_batches(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    N=G.number_of_nodes()\n",
    "    batch_size = N//100\n",
    "    SUM=0\n",
    "    if type(sorted_nodes[0])==tuple:\n",
    "\n",
    "        for i in range(50):\n",
    "            for j in range(batch_size):\n",
    "                n = sorted_nodes[i*batch_size+j][0]\n",
    "                G.remove_node(n)\n",
    "            lcc = compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "    \n",
    "    else:\n",
    "        for i in range(50):\n",
    "            for j in range(batch_size):\n",
    "                n = sorted_nodes[i*batch_size+j]\n",
    "                G.remove_node(n)\n",
    "            lcc = compute_lcc(G)/N\n",
    "            SUM+=lcc\n",
    "\n",
    "    return SUM/100\n",
    "\n",
    "\n",
    "def random_attack(g):\n",
    "    G=g.copy()\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes)\n",
    "    #divide the nodes into 100 batches\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            n = nodes[i*batch_size+j]\n",
    "            G.remove_node(n)\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        LCC[i] = lcc/fix\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return LCC, Inter, E\n",
    "\n",
    "def random_attack_edge(g):\n",
    "    '''returns the graph after a random attack of the edge'''\n",
    "    G = g.copy()\n",
    "    edges = list(G.edges())\n",
    "    random.shuffle(edges)\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            e = edges[i*batch_size+j]\n",
    "            G.remove_edge(e[0], e[1])\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        LCC[i] = lcc/fix\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return LCC, Inter, E\n",
    "\n",
    "def attack(g, sorted_nodes):\n",
    "    G=g.copy()\n",
    "    fix=G.number_of_nodes()\n",
    "    batch_size = fix//100\n",
    "    norm_LCC={}\n",
    "    LCC={}\n",
    "    Inter={}\n",
    "    E={}\n",
    "    lcc_i = max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "    for i in range(50):\n",
    "        for j in range(batch_size):\n",
    "            n = sorted_nodes[i*batch_size+j]\n",
    "            G.remove_node(n)\n",
    "        lcc = compute_lcc(G)\n",
    "        i_index= compute_i(G, lcc_i)\n",
    "        norm_LCC[i] = lcc/fix\n",
    "        LCC[i]=lcc\n",
    "        Inter[i]=i_index\n",
    "        E[i]=nx.algorithms.global_efficiency(G)\n",
    "    return norm_LCC, Inter, E, LCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading networks\n",
    "\n",
    "* Loading the network\n",
    "* Extract some properties:\n",
    "  * Compute statistics\n",
    "  * Get degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arenas_email = nx.read_gml('../benchmark/arenas-email.gml', label='id')\n",
    "bn_cat_mixed_species_brain_1 = nx.read_gml('../benchmark/bn-cat-mixed-species_brain_1.gml', label='id')\n",
    "bn_macaque_rhesus_brain_2 = nx.read_gml('../benchmark/bn-macaque-rhesus_brain_2.gml', label='id')\n",
    "circuits_s208 = nx.read_gml('../benchmark/circuits s208.gml', label='id')\n",
    "circuits_s420 = nx.read_gml('../benchmark/circuits s420.gml', label='id')\n",
    "circuits_s838 = nx.read_gml('../benchmark/circuits s838.gml', label='id')\n",
    "dolphins = nx.read_gml('../benchmark/dolphins.gml', label='id')\n",
    "e_coli = nx.read_gml('../benchmark/E. coli.gml', label='id')\n",
    "facebook_0 = nx.read_gml('../benchmark/facebook 0.gml', label='id')\n",
    "facebook_107 = nx.read_gml('../benchmark/facebook 107.gml', label='id')\n",
    "facebook_1684 = nx.read_gml('../benchmark/facebook 1684.gml', label='id')\n",
    "facebook_348 = nx.read_gml('../benchmark/facebook 348.gml', label='id')\n",
    "facebook_414 = nx.read_gml('../benchmark/facebook 414.gml', label='id')\n",
    "facebook_686 = nx.read_gml('../benchmark/facebook 686.gml', label='id')\n",
    "fb_pages_food = nx.read_gml('../benchmark/fb-pages-food.gml', label='id')\n",
    "karate = nx.read_gml('../benchmark/Karate.gml', label='id')\n",
    "polbooks = nx.read_gml('../benchmark/polbooks.gml', label='id')\n",
    "soc_firm_hi_tech = nx.read_gml('../benchmark/soc-firm-hi-tech.gml', label='id')\n",
    "soc_tribes = nx.read_gml('../benchmark/soc-tribes.gml', label='id')\n",
    "word_adjacencies = nx.read_gml('../benchmark/word_adjacencies.gml', label='id')\n",
    "\n",
    "net_911=nx.read_gml('../benchmark/911.gml', label='id')\n",
    "corruption=nx.read_gml('../benchmark/corruption.gml', label='id')\n",
    "crime_net=nx.read_gml('../benchmark/CrimeNet.gml', label='id')\n",
    "digg=nx.read_gml('../benchmark/Digg.gml', label='id')\n",
    "email=nx.read_gml('../benchmark/Email.gml', label='id')\n",
    "jazz=nx.read_gml('../benchmark/Jazz.gml', label='id')\n",
    "petster_hamster=nx.read_gml('../benchmark/Petster-Hamster.gml', label='id')\n",
    "router=nx.read_gml('../benchmark/Router.gml', label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Attack\n",
    "\n",
    "Random attacks applied to all the networks, all are divided to 100 batches, attack is up to 50% of the nodes/edges:\n",
    "* nodes attacks \n",
    "* edges attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------#\n",
    "#nodes random attacks:\n",
    "\n",
    "random_arenas_email_attack = random_attack(arenas_email)\n",
    "random_bn_cat_mixed_species_brain_1_attack = random_attack(bn_cat_mixed_species_brain_1)\n",
    "random_bn_macaque_rhesus_brain_2_attack = random_attack(bn_macaque_rhesus_brain_2)\n",
    "random_circuits_s208_attack = random_attack(circuits_s208)\n",
    "random_circuits_s420_attack = random_attack(circuits_s420)\n",
    "random_circuits_s838_attack = random_attack(circuits_s838)\n",
    "random_dolphins_attack = random_attack(dolphins)\n",
    "random_e_coli_attack = random_attack(e_coli)\n",
    "random_facebook_0_attack = random_attack(facebook_0)\n",
    "random_facebook_107_attack = random_attack(facebook_107)\n",
    "random_facebook_1684_attack = random_attack(facebook_1684)\n",
    "random_facebook_348_attack = random_attack(facebook_348)\n",
    "random_facebook_414_attack = random_attack(facebook_414)\n",
    "random_facebook_686_attack = random_attack(facebook_686)\n",
    "random_fb_pages_food_attack = random_attack(fb_pages_food)\n",
    "random_karate_attack = random_attack(karate)\n",
    "random_polbooks_attack = random_attack(polbooks)\n",
    "random_soc_firm_hi_tech_attack = random_attack(soc_firm_hi_tech)\n",
    "random_soc_tribes_attack = random_attack(soc_tribes)\n",
    "random_word_adjacencies_attack = random_attack(word_adjacencies)\n",
    "\n",
    "random_net911_attack = random_attack(net_911)\n",
    "random_corruption_attack = random_attack(corruption)\n",
    "random_crime_net_attack = random_attack(crime_net)\n",
    "random_email_attack = random_attack(email)\n",
    "random_jazz_attack = random_attack(jazz)\n",
    "random_petster_hamster_attack = random_attack(petster_hamster)\n",
    "random_router_attack = random_attack(router)\n",
    "# random_digg_attack = random_attack(digg)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------#\n",
    "#edges random attacks:\n",
    "\n",
    "random_arenas_email_attack_edge= random_attack_edge(arenas_email)\n",
    "random_bn_cat_mixed_species_brain_1_attack_edge= random_attack_edge(bn_cat_mixed_species_brain_1)\n",
    "random_bn_macaque_rhesus_brain_2_attack_edge= random_attack_edge(bn_macaque_rhesus_brain_2)\n",
    "random_circuits_s208_attack_edge= random_attack_edge(circuits_s208)\n",
    "random_circuits_s420_attack_edge= random_attack_edge(circuits_s420)\n",
    "random_circuits_s838_attack_edge= random_attack_edge(circuits_s838)\n",
    "random_dolphins_attack_edge= random_attack_edge(dolphins)\n",
    "random_e_coli_attack_edge= random_attack_edge(e_coli)\n",
    "random_facebook_0_attack_edge= random_attack_edge(facebook_0)\n",
    "random_facebook_107_attack_edge= random_attack_edge(facebook_107)\n",
    "random_facebook_1684_attack_edge= random_attack_edge(facebook_1684)\n",
    "random_facebook_348_attack_edge= random_attack_edge(facebook_348)\n",
    "random_facebook_414_attack_edge= random_attack_edge(facebook_414)\n",
    "random_facebook_686_attack_edge= random_attack_edge(facebook_686)\n",
    "random_fb_pages_food_attack_edge= random_attack_edge(fb_pages_food)\n",
    "random_karate_attack_edge= random_attack_edge(karate)\n",
    "random_polbooks_attack_edge= random_attack_edge(polbooks)\n",
    "random_soc_firm_hi_tech_attack_edge= random_attack_edge(soc_firm_hi_tech)\n",
    "random_soc_tribes_attack_edge= random_attack_edge(soc_tribes)\n",
    "random_word_adjacencies_attack_edge= random_attack_edge(word_adjacencies)\n",
    "\n",
    "random_net911_attack_edge= random_attack_edge(net_911)\n",
    "random_corruption_attack_edge= random_attack_edge(corruption)\n",
    "random_crime_net_attack_edge= random_attack_edge(crime_net)\n",
    "random_email_attack_edge= random_attack_edge(email)\n",
    "random_jazz_attack_edge= random_attack_edge(jazz)\n",
    "random_petster_hamster_attack_edge= random_attack_edge(petster_hamster)\n",
    "random_router_attack_edge= random_attack_edge(router)\n",
    "# random_digg_attack_edge= random_attack_edge(digg)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality-based Targeted Attack\n",
    "---------------------------\n",
    "\n",
    "* Nodes centralities:\n",
    "  * Betweenness centrality\n",
    "  * Closeness centrality\n",
    "  * Degree centrality\n",
    "  * PLCi centrality\n",
    "  * Percolaion centrality\n",
    "  * Proximity centrality\n",
    "  * Mapping Entropy Betweenness centrality\n",
    "  * Mapping Entropy Closeness centrality\n",
    "  * Mapping Entropy Degree centrality   \n",
    "\n",
    "----------------\n",
    "\n",
    "* Edges centralities:\n",
    "  * Betweenness centrality\n",
    "\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node centralities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality_sorted_arenas_email = sorted(nx.betweenness_centrality(arenas_email).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_bn_cat_mixed_species_brain_1 = sorted(nx.betweenness_centrality(bn_cat_mixed_species_brain_1).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_bn_macaque_rhesus_brain_2 = sorted(nx.betweenness_centrality(bn_macaque_rhesus_brain_2).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_circuits_s208 = sorted(nx.betweenness_centrality(circuits_s208).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_circuits_s420 = sorted(nx.betweenness_centrality(circuits_s420).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_circuits_s838 = sorted(nx.betweenness_centrality(circuits_s838).items(), key=lambda x: x[1], reverse=True) \n",
    "betweenness_centrality_sorted_dolphins = sorted(nx.betweenness_centrality(dolphins).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_e_coli = sorted(nx.betweenness_centrality(e_coli).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_0 = sorted(nx.betweenness_centrality(facebook_0).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_107 = sorted(nx.betweenness_centrality(facebook_107).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_1684 = sorted(nx.betweenness_centrality(facebook_1684).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_348 = sorted(nx.betweenness_centrality(facebook_348).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_414 = sorted(nx.betweenness_centrality(facebook_414).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_facebook_686 = sorted(nx.betweenness_centrality(facebook_686).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_fb_pages_food = sorted(nx.betweenness_centrality(fb_pages_food).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_karate = sorted(nx.betweenness_centrality(karate).items(), key=lambda x: x[1], reverse=True)   \n",
    "betweenness_centrality_sorted_polbooks = sorted(nx.betweenness_centrality(polbooks).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_soc_firm_hi_tech = sorted(nx.betweenness_centrality(soc_firm_hi_tech).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_soc_tribes = sorted(nx.betweenness_centrality(soc_tribes).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_word_adjacencies = sorted(nx.betweenness_centrality(word_adjacencies).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_net911 = sorted(nx.betweenness_centrality(net_911).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_corruption = sorted(nx.betweenness_centrality(corruption).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_crime_net = sorted(nx.betweenness_centrality(crime_net).items(), key=lambda x: x[1], reverse=True)\n",
    "# betweenness_centrality_sorted_digg = sorted(nx.betweenness_centrality(digg).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_jazz = sorted(nx.betweenness_centrality(jazz).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_petster_hamster = sorted(nx.betweenness_centrality(petster_hamster).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_router = sorted(nx.betweenness_centrality(router).items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_centrality_sorted_email = sorted(nx.betweenness_centrality(email).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "closeness_centrality_sorted_arenas_email = sorted(nx.closeness_centrality(arenas_email).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_bn_cat_mixed_species_brain_1 = sorted(nx.closeness_centrality(bn_cat_mixed_species_brain_1).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_bn_macaque_rhesus_brain_2 = sorted(nx.closeness_centrality(bn_macaque_rhesus_brain_2).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_circuits_s208 = sorted(nx.closeness_centrality(circuits_s208).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_circuits_s420 = sorted(nx.closeness_centrality(circuits_s420).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_circuits_s838 = sorted(nx.closeness_centrality(circuits_s838).items(), key=lambda x: x[1], reverse=True) \n",
    "closeness_centrality_sorted_dolphins = sorted(nx.closeness_centrality(dolphins).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_e_coli = sorted(nx.closeness_centrality(e_coli).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_0 = sorted(nx.closeness_centrality(facebook_0).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_107 = sorted(nx.closeness_centrality(facebook_107).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_1684 = sorted(nx.closeness_centrality(facebook_1684).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_348 = sorted(nx.closeness_centrality(facebook_348).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_414 = sorted(nx.closeness_centrality(facebook_414).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_facebook_686 = sorted(nx.closeness_centrality(facebook_686).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_fb_pages_food = sorted(nx.closeness_centrality(fb_pages_food).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_karate = sorted(nx.closeness_centrality(karate).items(), key=lambda x: x[1], reverse=True)   \n",
    "closeness_centrality_sorted_polbooks = sorted(nx.closeness_centrality(polbooks).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_soc_firm_hi_tech = sorted(nx.closeness_centrality(soc_firm_hi_tech).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_soc_tribes = sorted(nx.closeness_centrality(soc_tribes).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_word_adjacencies = sorted(nx.closeness_centrality(word_adjacencies).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_net911 = sorted(nx.closeness_centrality(net_911).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_corruption = sorted(nx.closeness_centrality(corruption).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_crime_net = sorted(nx.closeness_centrality(crime_net).items(), key=lambda x: x[1], reverse=True)\n",
    "# closeness_centrality_sorted_digg = sorted(nx.closeness_centrality(digg).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_jazz = sorted(nx.closeness_centrality(jazz).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_petster_hamster = sorted(nx.closeness_centrality(petster_hamster).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_router = sorted(nx.closeness_centrality(router).items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_centrality_sorted_email = sorted(nx.closeness_centrality(email).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "degree_centrality_sorted_arenas_email = sorted(nx.degree_centrality(arenas_email).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_bn_cat_mixed_species_brain_1 = sorted(nx.degree_centrality(bn_cat_mixed_species_brain_1).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_bn_macaque_rhesus_brain_2 = sorted(nx.degree_centrality(bn_macaque_rhesus_brain_2).items(), key=lambda x: x[1], reverse=True) \n",
    "degree_centrality_sorted_circuits_s208 = sorted(nx.degree_centrality(circuits_s208).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_circuits_s420 = sorted(nx.degree_centrality(circuits_s420).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_circuits_s838 = sorted(nx.degree_centrality(circuits_s838).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_dolphins = sorted(nx.degree_centrality(dolphins).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_e_coli = sorted(nx.degree_centrality(e_coli).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_0 = sorted(nx.degree_centrality(facebook_0).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_107 = sorted(nx.degree_centrality(facebook_107).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_1684 = sorted(nx.degree_centrality(facebook_1684).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_348 = sorted(nx.degree_centrality(facebook_348).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_414 = sorted(nx.degree_centrality(facebook_414).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_facebook_686 = sorted(nx.degree_centrality(facebook_686).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_fb_pages_food = sorted(nx.degree_centrality(fb_pages_food).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_karate = sorted(nx.degree_centrality(karate).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_polbooks = sorted(nx.degree_centrality(polbooks).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_soc_firm_hi_tech = sorted(nx.degree_centrality(soc_firm_hi_tech).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_soc_tribes = sorted(nx.degree_centrality(soc_tribes).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_word_adjacencies = sorted(nx.degree_centrality(word_adjacencies).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_net911 = sorted(nx.degree_centrality(net_911).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_corruption = sorted(nx.degree_centrality(corruption).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_crime_net = sorted(nx.degree_centrality(crime_net).items(), key=lambda x: x[1], reverse=True)\n",
    "# degree_centrality_sorted_digg = sorted(nx.degree_centrality(digg).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_jazz = sorted(nx.degree_centrality(jazz).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_petster_hamster = sorted(nx.degree_centrality(petster_hamster).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_router = sorted(nx.degree_centrality(router).items(), key=lambda x: x[1], reverse=True)\n",
    "degree_centrality_sorted_email = sorted(nx.degree_centrality(email).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "bet_attack_arenas_email = attack(arenas_email, [x[0] for x in betweenness_centrality_sorted_arenas_email])\n",
    "bet_attack_bn_cat_mixed_species_brain_1 = attack(bn_cat_mixed_species_brain_1, [x[0] for x in betweenness_centrality_sorted_bn_cat_mixed_species_brain_1])\n",
    "bet_attack_bn_macaque_rhesus_brain_2 = attack(bn_macaque_rhesus_brain_2, [x[0] for x in betweenness_centrality_sorted_bn_macaque_rhesus_brain_2])\n",
    "bet_attack_circuits_s208 = attack(circuits_s208, [x[0] for x in betweenness_centrality_sorted_circuits_s208])\n",
    "bet_attack_circuits_s420 = attack(circuits_s420, [x[0] for x in betweenness_centrality_sorted_circuits_s420])\n",
    "bet_attack_circuits_s838 = attack(circuits_s838, [x[0] for x in betweenness_centrality_sorted_circuits_s838])\n",
    "bet_attack_dolphins = attack(dolphins, [x[0] for x in betweenness_centrality_sorted_dolphins])\n",
    "bet_attack_e_coli = attack(e_coli, [x[0] for x in betweenness_centrality_sorted_e_coli])\n",
    "bet_attack_facebook_0 = attack(facebook_0, [x[0] for x in betweenness_centrality_sorted_facebook_0])\n",
    "bet_attack_facebook_107 = attack(facebook_107, [x[0] for x in betweenness_centrality_sorted_facebook_107])\n",
    "bet_attack_facebook_1684 = attack(facebook_1684, [x[0] for x in betweenness_centrality_sorted_facebook_1684])\n",
    "bet_attack_facebook_348 = attack(facebook_348, [x[0] for x in betweenness_centrality_sorted_facebook_348])\n",
    "bet_attack_facebook_414 = attack(facebook_414, [x[0] for x in betweenness_centrality_sorted_facebook_414])\n",
    "bet_attack_facebook_686 = attack(facebook_686, [x[0] for x in betweenness_centrality_sorted_facebook_686])\n",
    "bet_attack_fb_pages_food = attack(fb_pages_food, [x[0] for x in betweenness_centrality_sorted_fb_pages_food])\n",
    "bet_attack_karate = attack(karate, [x[0] for x in betweenness_centrality_sorted_karate])\n",
    "bet_attack_polbooks = attack(polbooks, [x[0] for x in betweenness_centrality_sorted_polbooks])\n",
    "bet_attack_soc_firm_hi_tech = attack(soc_firm_hi_tech, [x[0] for x in betweenness_centrality_sorted_soc_firm_hi_tech])\n",
    "bet_attack_soc_tribes = attack(soc_tribes, [x[0] for x in betweenness_centrality_sorted_soc_tribes])\n",
    "bet_attack_word_adjacencies = attack(word_adjacencies, [x[0] for x in betweenness_centrality_sorted_word_adjacencies])\n",
    "bet_attack_net911 = attack(net_911, [x[0] for x in betweenness_centrality_sorted_net911])\n",
    "bet_attack_corruption = attack(corruption, [x[0] for x in betweenness_centrality_sorted_corruption])\n",
    "bet_attack_crime_net = attack(crime_net, [x[0] for x in betweenness_centrality_sorted_crime_net])\n",
    "# bet_attack_digg = attack(digg, [x[0] for x in betweenness_centrality_sorted_digg])\n",
    "bet_attack_jazz = attack(jazz, [x[0] for x in betweenness_centrality_jazz])\n",
    "bet_attack_petster_hamster = attack(petster_hamster, [x[0] for x in betweenness_centrality_sorted_petster_hamster])\n",
    "bet_attack_router = attack(router, [x[0] for x in betweenness_centrality_sorted_router])\n",
    "bet_attack_email = attack(email, [x[0] for x in betweenness_centrality_sorted_email])\n",
    "\n",
    "clos_attack_arenas_email = attack(arenas_email, [x[0] for x in closeness_centrality_sorted_arenas_email])\n",
    "clos_attack_bn_cat_mixed_species_brain_1 = attack(bn_cat_mixed_species_brain_1, [x[0] for x in closeness_centrality_sorted_bn_cat_mixed_species_brain_1])\n",
    "clos_attack_bn_macaque_rhesus_brain_2 = attack(bn_macaque_rhesus_brain_2, [x[0] for x in closeness_centrality_sorted_bn_macaque_rhesus_brain_2])\n",
    "clos_attack_circuits_s208 = attack(circuits_s208, [x[0] for x in closeness_centrality_sorted_circuits_s208])\n",
    "clos_attack_circuits_s420 = attack(circuits_s420, [x[0] for x in closeness_centrality_sorted_circuits_s420])\n",
    "clos_attack_circuits_s838 = attack(circuits_s838, [x[0] for x in closeness_centrality_sorted_circuits_s838])\n",
    "clos_attack_dolphins = attack(dolphins, [x[0] for x in closeness_centrality_sorted_dolphins])\n",
    "clos_attack_e_coli = attack(e_coli, [x[0] for x in closeness_centrality_sorted_e_coli])\n",
    "clos_attack_facebook_0 = attack(facebook_0, [x[0] for x in closeness_centrality_sorted_facebook_0])\n",
    "clos_attack_facebook_107 = attack(facebook_107, [x[0] for x in closeness_centrality_sorted_facebook_107])\n",
    "clos_attack_facebook_1684 = attack(facebook_1684, [x[0] for x in closeness_centrality_sorted_facebook_1684])\n",
    "clos_attack_facebook_348 = attack(facebook_348, [x[0] for x in closeness_centrality_sorted_facebook_348])\n",
    "clos_attack_facebook_414 = attack(facebook_414, [x[0] for x in closeness_centrality_sorted_facebook_414])\n",
    "clos_attack_facebook_686 = attack(facebook_686, [x[0] for x in closeness_centrality_sorted_facebook_686])\n",
    "clos_attack_fb_pages_food = attack(fb_pages_food, [x[0] for x in closeness_centrality_sorted_fb_pages_food])\n",
    "clos_attack_karate = attack(karate, [x[0] for x in closeness_centrality_sorted_karate])\n",
    "clos_attack_polbooks = attack(polbooks, [x[0] for x in closeness_centrality_sorted_polbooks])\n",
    "clos_attack_soc_firm_hi_tech = attack(soc_firm_hi_tech, [x[0] for x in closeness_centrality_sorted_soc_firm_hi_tech])\n",
    "clos_attack_soc_tribes = attack(soc_tribes, [x[0] for x in closeness_centrality_sorted_soc_tribes])\n",
    "clos_attack_word_adjacencies = attack(word_adjacencies, [x[0] for x in closeness_centrality_sorted_word_adjacencies])\n",
    "clos_attack_net911 = attack(net_911, [x[0] for x in closeness_centrality_sorted_net911])\n",
    "clos_attack_corruption = attack(corruption, [x[0] for x in closeness_centrality_sorted_corruption])\n",
    "clos_attack_crime_net = attack(crime_net, [x[0] for x in closeness_centrality_sorted_crime_net])\n",
    "# clos_attack_digg = attack(digg, [x[0] for x in closeness_centrality_sorted_digg])\n",
    "clos_attack_jazz = attack(jazz, [x[0] for x in closeness_centrality_jazz])\n",
    "clos_attack_petster_hamster = attack(petster_hamster, [x[0] for x in closeness_centrality_sorted_petster_hamster])\n",
    "clos_attack_router = attack(router, [x[0] for x in closeness_centrality_sorted_router])\n",
    "clos_attack_email = attack(email, [x[0] for x in closeness_centrality_sorted_email])\n",
    "\n",
    "deg_attack_arenas_email = attack(arenas_email, [x[0] for x in degree_centrality_sorted_arenas_email])\n",
    "deg_attack_bn_cat_mixed_species_brain_1 = attack(bn_cat_mixed_species_brain_1, [x[0] for x in degree_centrality_sorted_bn_cat_mixed_species_brain_1])\n",
    "deg_attack_bn_macaque_rhesus_brain_2 = attack(bn_macaque_rhesus_brain_2, [x[0] for x in degree_centrality_sorted_bn_macaque_rhesus_brain_2])\n",
    "deg_attack_circuits_s208 = attack(circuits_s208, [x[0] for x in degree_centrality_sorted_circuits_s208])\n",
    "deg_attack_circuits_s420 = attack(circuits_s420, [x[0] for x in degree_centrality_sorted_circuits_s420])\n",
    "deg_attack_circuits_s838 = attack(circuits_s838, [x[0] for x in degree_centrality_sorted_circuits_s838])\n",
    "deg_attack_dolphins = attack(dolphins, [x[0] for x in degree_centrality_sorted_dolphins])\n",
    "deg_attack_e_coli = attack(e_coli, [x[0] for x in degree_centrality_sorted_e_coli])\n",
    "deg_attack_facebook_0 = attack(facebook_0, [x[0] for x in degree_centrality_sorted_facebook_0])\n",
    "deg_attack_facebook_107 = attack(facebook_107, [x[0] for x in degree_centrality_sorted_facebook_107])\n",
    "deg_attack_facebook_1684 = attack(facebook_1684, [x[0] for x in degree_centrality_sorted_facebook_1684])\n",
    "deg_attack_facebook_348 = attack(facebook_348, [x[0] for x in degree_centrality_sorted_facebook_348])\n",
    "deg_attack_facebook_414 = attack(facebook_414, [x[0] for x in degree_centrality_sorted_facebook_414])\n",
    "deg_attack_facebook_686 = attack(facebook_686, [x[0] for x in degree_centrality_sorted_facebook_686])\n",
    "deg_attack_fb_pages_food = attack(fb_pages_food, [x[0] for x in degree_centrality_sorted_fb_pages_food])\n",
    "deg_attack_karate = attack(karate, [x[0] for x in degree_centrality_sorted_karate])\n",
    "deg_attack_polbooks = attack(polbooks, [x[0] for x in degree_centrality_sorted_polbooks])\n",
    "deg_attack_soc_firm_hi_tech = attack(soc_firm_hi_tech, [x[0] for x in degree_centrality_sorted_soc_firm_hi_tech])\n",
    "deg_attack_soc_tribes = attack(soc_tribes, [x[0] for x in degree_centrality_sorted_soc_tribes])\n",
    "deg_attack_word_adjacencies = attack(word_adjacencies, [x[0] for x in degree_centrality_sorted_word_adjacencies])\n",
    "deg_attack_net911 = attack(net_911, [x[0] for x in degree_centrality_sorted_net911])\n",
    "deg_attack_corruption = attack(corruption, [x[0] for x in degree_centrality_sorted_corruption])\n",
    "deg_attack_crime_net = attack(crime_net, [x[0] for x in degree_centrality_sorted_crime_net])\n",
    "# deg_attack_digg = attack(digg, [x[0] for x in degree_centrality_sorted_digg])\n",
    "deg_attack_jazz = attack(jazz, [x[0] for x in degree_centrality_jazz])\n",
    "deg_attack_petster_hamster = attack(petster_hamster, [x[0] for x in degree_centrality_sorted_petster_hamster])\n",
    "deg_attack_router = attack(router, [x[0] for x in degree_centrality_sorted_router])\n",
    "deg_attack_email = attack(email, [x[0] for x in degree_centrality_sorted_email])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arenas_email_complex_df = pd.read_csv('../results/resultsarenas_email.csv', skiprows=1, header=None)\n",
    "plci_arenas_email = dict(zip(arenas_email_complex_df[0], arenas_email_complex_df[1]))\n",
    "plci_arenas_email_sorted = sorted(plci_arenas_email.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_arenas_email_nodes =[x[0]-1 for x in plci_arenas_email_sorted]\n",
    "percolation_arenas_email = dict(zip(arenas_email_complex_df[0], arenas_email_complex_df[2]))\n",
    "percolation_arenas_email_sorted = sorted(percolation_arenas_email.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_arenas_email_nodes =[x[0]-1 for x in percolation_arenas_email_sorted]\n",
    "\n",
    "bn_cat_mixed_species_brain_1_complex_df = pd.read_csv('../results/resultsbn_cat_mixed_species_brain_1.csv', skiprows=1, header=None)\n",
    "plci_bn_cat_mixed_species_brain_1 = dict(zip(bn_cat_mixed_species_brain_1_complex_df[0], bn_cat_mixed_species_brain_1_complex_df[1]))\n",
    "plci_bn_cat_mixed_species_brain_1_sorted = sorted(plci_bn_cat_mixed_species_brain_1.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_bn_cat_mixed_species_brain_1_nodes =[x[0]-1 for x in plci_bn_cat_mixed_species_brain_1_sorted]\n",
    "percolation_bn_cat_mixed_species_brain_1 = dict(zip(bn_cat_mixed_species_brain_1_complex_df[0], bn_cat_mixed_species_brain_1_complex_df[2]))\n",
    "percolation_bn_cat_mixed_species_brain_1_sorted = sorted(percolation_bn_cat_mixed_species_brain_1.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_bn_cat_mixed_species_brain_1_nodes =[x[0]-1 for x in percolation_bn_cat_mixed_species_brain_1_sorted]\n",
    "\n",
    "bn_macaque_rhesus_brain_2_complex_df = pd.read_csv('../results/resultsbn_macaque_rhesus_brain_2.csv', skiprows=1, header=None)\n",
    "plci_bn_macaque_rhesus_brain_2 = dict(zip(bn_macaque_rhesus_brain_2_complex_df[0], bn_macaque_rhesus_brain_2_complex_df[1]))\n",
    "plci_bn_macaque_rhesus_brain_2_sorted = sorted(plci_bn_macaque_rhesus_brain_2.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_bn_macaque_rhesus_brain_2_nodes =[x[0]-1 for x in plci_bn_macaque_rhesus_brain_2_sorted]\n",
    "percolation_bn_macaque_rhesus_brain_2 = dict(zip(bn_macaque_rhesus_brain_2_complex_df[0], bn_macaque_rhesus_brain_2_complex_df[2]))\n",
    "percolation_bn_macaque_rhesus_brain_2_sorted = sorted(percolation_bn_macaque_rhesus_brain_2.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_bn_macaque_rhesus_brain_2_nodes =[x[0]-1 for x in percolation_bn_macaque_rhesus_brain_2_sorted]\n",
    "\n",
    "circuits_s208_complex_df = pd.read_csv('../results/resultscircuits s208.csv', skiprows=1, header=None)\n",
    "plci_circuits_s208 = dict(zip(circuits_s208_complex_df[0], circuits_s208_complex_df[1]))\n",
    "plci_circuits_s208_sorted = sorted(plci_circuits_s208.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_circuits_s208_nodes =[x[0]-1 for x in plci_circuits_s208_sorted]\n",
    "percolation_circuits_s208 = dict(zip(circuits_s208_complex_df[0], circuits_s208_complex_df[2]))\n",
    "percolation_circuits_s208_sorted = sorted(percolation_circuits_s208.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_circuits_s208_nodes =[x[0]-1 for x in percolation_circuits_s208_sorted]\n",
    "\n",
    "circuits_s420_complex_df = pd.read_csv('../results/resultscircuits s420.csv', skiprows=1, header=None)\n",
    "plci_circuits_s420 = dict(zip(circuits_s420_complex_df[0], circuits_s420_complex_df[1]))\n",
    "plci_circuits_s420_sorted = sorted(plci_circuits_s420.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_circuits_s420_nodes =[x[0]-1 for x in plci_circuits_s420_sorted]\n",
    "percolation_circuits_s420 = dict(zip(circuits_s420_complex_df[0], circuits_s420_complex_df[2]))\n",
    "percolation_circuits_s420_sorted = sorted(percolation_circuits_s420.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_circuits_s420_nodes =[x[0]-1 for x in percolation_circuits_s420_sorted]\n",
    "\n",
    "circuits_s838_complex_df = pd.read_csv('../results/resultscircuits s838.csv', skiprows=1, header=None)\n",
    "plci_circuits_s838 = dict(zip(circuits_s838_complex_df[0], circuits_s838_complex_df[1]))\n",
    "plci_circuits_s838_sorted = sorted(plci_circuits_s838.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_circuits_s838_nodes =[x[0]-1 for x in plci_circuits_s838_sorted]\n",
    "percolation_circuits_s838 = dict(zip(circuits_s838_complex_df[0], circuits_s838_complex_df[2]))\n",
    "percolation_circuits_s838_sorted = sorted(percolation_circuits_s838.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_circuits_s838_nodes =[x[0]-1 for x in percolation_circuits_s838_sorted]\n",
    "\n",
    "dolphins_complex_df = pd.read_csv('../results/resultsdolphins.csv', skiprows=1, header=None)\n",
    "plci_dolphins = dict(zip(dolphins_complex_df[0], dolphins_complex_df[1]))\n",
    "plci_dolphins_sorted = sorted(plci_dolphins.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_dolphins_nodes =[x[0]-1 for x in plci_dolphins_sorted]\n",
    "percolation_dolphins = dict(zip(dolphins_complex_df[0], dolphins_complex_df[2]))\n",
    "percolation_dolphins_sorted = sorted(percolation_dolphins.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_dolphins_nodes =[x[0]-1 for x in percolation_dolphins_sorted]\n",
    "\n",
    "e_coli_complex_df = pd.read_csv('../results/resultsE. coli.csv', skiprows=1, header=None)\n",
    "plci_e_coli = dict(zip(e_coli_complex_df[0], e_coli_complex_df[1]))\n",
    "plci_e_coli_sorted = sorted(plci_e_coli.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_e_coli_nodes =[x[0]-1 for x in plci_e_coli_sorted]\n",
    "percolation_e_coli = dict(zip(e_coli_complex_df[0], e_coli_complex_df[2]))\n",
    "percolation_e_coli_sorted = sorted(percolation_e_coli.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_e_coli_nodes =[x[0]-1 for x in percolation_e_coli_sorted]\n",
    "\n",
    "facebook_0_complex_df = pd.read_csv('../results/resultsfacebook 0.csv', skiprows=1, header=None)\n",
    "plci_facebook_0 = dict(zip(facebook_0_complex_df[0], facebook_0_complex_df[1]))\n",
    "plci_facebook_0_sorted = sorted(plci_facebook_0.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_facebook_0_nodes =[x[0]-1 for x in plci_facebook_0_sorted]\n",
    "percolation_facebook_0 = dict(zip(facebook_0_complex_df[0], facebook_0_complex_df[2]))\n",
    "percolation_facebook_0_sorted = sorted(percolation_facebook_0.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_facebook_0_nodes =[x[0]-1 for x in percolation_facebook_0_sorted]\n",
    "\n",
    "facebook_107_complex_df = pd.read_csv('../results/resultsfacebook 107.csv', skiprows=1, header=None)\n",
    "plci_facebook_107 = dict(zip(facebook_107_complex_df[0], facebook_107_complex_df[1]))\n",
    "plci_facebook_107_sorted = sorted(plci_facebook_107.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_facebook_107_nodes =[x[0]-1 for x in plci_facebook_107_sorted]\n",
    "percolation_facebook_107 = dict(zip(facebook_107_complex_df[0], facebook_107_complex_df[2]))\n",
    "percolation_facebook_107_sorted = sorted(percolation_facebook_107.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_facebook_107_nodes =[x[0]-1 for x in percolation_facebook_107_sorted]\n",
    "\n",
    "facebook_1684_complex_df = pd.read_csv('../results/resultsfacebook 1684.csv', skiprows=1, header=None)\n",
    "plci_facebook_1684 = dict(zip(facebook_1684_complex_df[0], facebook_1684_complex_df[1]))\n",
    "plci_facebook_1684_sorted = sorted(plci_facebook_1684.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_facebook_1684_nodes =[x[0]-1 for x in plci_facebook_1684_sorted]\n",
    "percolation_facebook_1684 = dict(zip(facebook_1684_complex_df[0], facebook_1684_complex_df[2]))\n",
    "percolation_facebook_1684_sorted = sorted(percolation_facebook_1684.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_facebook_1684_nodes =[x[0]-1 for x in percolation_facebook_1684_sorted]\n",
    "\n",
    "facebook_348_complex_df = pd.read_csv('../results/resultsfacebook 348.csv', skiprows=1, header=None)\n",
    "plci_facebook_348 = dict(zip(facebook_348_complex_df[0], facebook_348_complex_df[1]))\n",
    "plci_facebook_348_sorted = sorted(plci_facebook_348.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_facebook_348_nodes =[x[0]-1 for x in plci_facebook_348_sorted]\n",
    "percolation_facebook_348 = dict(zip(facebook_348_complex_df[0], facebook_348_complex_df[2]))\n",
    "percolation_facebook_348_sorted = sorted(percolation_facebook_348.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_facebook_348_nodes =[x[0]-1 for x in percolation_facebook_348_sorted]\n",
    "\n",
    "facebook_414_complex_df = pd.read_csv('../results/resultsfacebook 414.csv', skiprows=1, header=None)\n",
    "plci_facebook_414 = dict(zip(facebook_414_complex_df[0], facebook_414_complex_df[1]))\n",
    "plci_facebook_414_sorted = sorted(plci_facebook_414.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_facebook_414_nodes =[x[0]-1 for x in plci_facebook_414_sorted]\n",
    "percolation_facebook_414 = dict(zip(facebook_414_complex_df[0], facebook_414_complex_df[2]))\n",
    "percolation_facebook_414_sorted = sorted(percolation_facebook_414.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_facebook_414_nodes =[x[0]-1 for x in percolation_facebook_414_sorted]\n",
    "\n",
    "facebook_686_complex_df = pd.read_csv('../results/resultsfacebook 686.csv', skiprows=1, header=None)\n",
    "plci_facebook_686 = dict(zip(facebook_686_complex_df[0], facebook_686_complex_df[1]))\n",
    "plci_facebook_686_sorted = sorted(plci_facebook_686.items(), key=lambda x: x[1], reverse=True)  \n",
    "plci_facebook_686_nodes =[x[0]-1 for x in plci_facebook_686_sorted]\n",
    "percolation_facebook_686 = dict(zip(facebook_686_complex_df[0], facebook_686_complex_df[2]))\n",
    "percolation_facebook_686_sorted = sorted(percolation_facebook_686.items(), key=lambda x: x[1], reverse=True)    \n",
    "percolation_facebook_686_nodes =[x[0]-1 for x in percolation_facebook_686_sorted]\n",
    "\n",
    "fb_pages_food_complex_df = pd.read_csv('../results/resultsfb_pages_food.csv', skiprows=1, header=None)\n",
    "plci_fb_pages_food = dict(zip(fb_pages_food_complex_df[0], fb_pages_food_complex_df[1]))\n",
    "plci_fb_pages_food_sorted = sorted(plci_fb_pages_food.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_fb_pages_food_nodes =[x[0]-1 for x in plci_fb_pages_food_sorted]\n",
    "percolation_fb_pages_food = dict(zip(fb_pages_food_complex_df[0], fb_pages_food_complex_df[2]))\n",
    "percolation_fb_pages_food_sorted = sorted(percolation_fb_pages_food.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_fb_pages_food_nodes =[x[0]-1 for x in percolation_fb_pages_food_sorted]\n",
    "\n",
    "karate_complex_df = pd.read_csv('../results/resultskarate.csv', skiprows=1, header=None)\n",
    "plci_karate = dict(zip(karate_complex_df[0], karate_complex_df[1])) \n",
    "plci_karate_sorted = sorted(plci_karate.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_karate_nodes =[x[0]-1 for x in plci_karate_sorted]\n",
    "percolation_karate = dict(zip(karate_complex_df[0], karate_complex_df[2]))\n",
    "percolation_karate_sorted = sorted(percolation_karate.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_karate_nodes =[x[0]-1 for x in percolation_karate_sorted]\n",
    "\n",
    "polbooks_complex_df = pd.read_csv('../results/resultspolbooks.csv', skiprows=1, header=None)\n",
    "plci_polbooks = dict(zip(polbooks_complex_df[0], polbooks_complex_df[1]))\n",
    "plci_polbooks_sorted = sorted(plci_polbooks.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_polbooks_nodes =[x[0]-1 for x in plci_polbooks_sorted]\n",
    "percolation_polbooks = dict(zip(polbooks_complex_df[0], polbooks_complex_df[2]))\n",
    "percolation_polbooks_sorted = sorted(percolation_polbooks.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_polbooks_nodes =[x[0]-1 for x in percolation_polbooks_sorted]\n",
    "\n",
    "soc_firm_hi_tech_complex_df = pd.read_csv('../results/resultssoc_firm_hi_tech.csv', skiprows=1, header=None)\n",
    "plci_soc_firm_hi_tech = dict(zip(soc_firm_hi_tech_complex_df[0], soc_firm_hi_tech_complex_df[1]))\n",
    "plci_soc_firm_hi_tech_sorted = sorted(plci_soc_firm_hi_tech.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_soc_firm_hi_tech_nodes =[x[0]-1 for x in plci_soc_firm_hi_tech_sorted]\n",
    "percolation_soc_firm_hi_tech = dict(zip(soc_firm_hi_tech_complex_df[0], soc_firm_hi_tech_complex_df[2]))\n",
    "percolation_soc_firm_hi_tech_sorted = sorted(percolation_soc_firm_hi_tech.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_soc_firm_hi_tech_nodes =[x[0]-1 for x in percolation_soc_firm_hi_tech_sorted]\n",
    "\n",
    "soc_tribes_complex_df = pd.read_csv('../results/resultssoc_tribes.csv', skiprows=1, header=None)\n",
    "plci_soc_tribes = dict(zip(soc_tribes_complex_df[0], soc_tribes_complex_df[1]))\n",
    "plci_soc_tribes_sorted = sorted(plci_soc_tribes.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_soc_tribes_nodes =[x[0]-1 for x in plci_soc_tribes_sorted]\n",
    "percolation_soc_tribes = dict(zip(soc_tribes_complex_df[0], soc_tribes_complex_df[2]))\n",
    "percolation_soc_tribes_sorted = sorted(percolation_soc_tribes.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_soc_tribes_nodes =[x[0]-1 for x in percolation_soc_tribes_sorted]\n",
    "\n",
    "word_adjacencies_complex_df = pd.read_csv('../results/resultsword_adjacencies.csv', skiprows=1, header=None)\n",
    "plci_word_adjacencies = dict(zip(word_adjacencies_complex_df[0], word_adjacencies_complex_df[1]))\n",
    "plci_word_adjacencies_sorted = sorted(plci_word_adjacencies.items(), key=lambda x: x[1], reverse=True)\n",
    "plci_word_adjacencies_nodes =[x[0]-1 for x in plci_word_adjacencies_sorted]\n",
    "percolation_word_adjacencies = dict(zip(word_adjacencies_complex_df[0], word_adjacencies_complex_df[2]))\n",
    "percolation_word_adjacencies_sorted = sorted(percolation_word_adjacencies.items(), key=lambda x: x[1], reverse=True)\n",
    "percolation_word_adjacencies_nodes =[x[0]-1 for x in percolation_word_adjacencies_sorted]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
